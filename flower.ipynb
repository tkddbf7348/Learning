{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpnQbx7bZfGj"
      },
      "source": [
        "import os, re, glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dropout, Activation, Dense\n",
        "from keras.layers import Flatten, Convolution2D, MaxPooling2D\n",
        "\n",
        "allow_pickle=True\n",
        "groups_folder_path = '/content/drive/MyDrive/Colab Notebooks/AI/flower_CNN/'\n",
        "categories = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "num_classes = len(categories)\n",
        "\n",
        "image_w = 32\n",
        "image_h = 32\n",
        "  \n",
        "X = []\n",
        "Y = []\n",
        "  \n",
        "for idex, categorie in enumerate(categories):\n",
        "    label = [0 for i in range(num_classes)]\n",
        "    label[idex] = 1\n",
        "    image_dir = groups_folder_path + categorie + '/'\n",
        "\n",
        "    for top, dirs, f in os.walk(image_dir):\n",
        "        for filename in f:\n",
        "            print(image_dir+filename)\n",
        "            img = cv2.imread(image_dir+filename)\n",
        "            img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
        "            X.append(img/256)\n",
        "            Y.append(label)\n",
        " \n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        " \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "xy = (X_train, X_test, Y_train, Y_test)\n",
        " \n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/AI/flower_CNN/img_data.npy\", xy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRfG60d9GjtQ"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOuMc5QJAgNt"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = np.load(\"/content/drive/MyDrive/Colab Notebooks/AI/flower_CNN/img_data.npy\", allow_pickle=True)\n",
        " \n",
        "model = Sequential()\n",
        "model.add(Convolution2D(16, 3, 3, border_mode='same', activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "  \n",
        "model.add(Convolution2D(64, 3, 3,  activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Convolution2D(64, 3, 3))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "  \n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation = 'softmax'))\n",
        "  \n",
        "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=100)\n",
        " \n",
        "model.save('flowers.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpfzAIqNAnHL"
      },
      "source": [
        "X_train = np.append(X_train, X_test, axis=0)\n",
        "Y_train = np.append(Y_train, Y_test, axis=0)\n",
        "\n",
        "# Save Model with CheckPoint & StopPoint\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "import os\n",
        "import datetime\n",
        " \n",
        "Datetime = datetime.datetime.now().strftime('%m%d_%H%M')\n",
        "modelpath=\"flowers.h5\"\n",
        " \n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='loss', patience=50)\n",
        " \n",
        "# Learning and save models\n",
        "model.fit(X_train, Y_train, validation_split=0.1, epochs=3500, batch_size=10, verbose=0, callbacks=[early_stopping_callback,checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myitXvF8AsEe"
      },
      "source": [
        "import os, re, glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from numpy import argmax\n",
        "from keras.models import load_model\n",
        " \n",
        "categories = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        " \n",
        "def Dataization(img_path):\n",
        "    image_w = 32\n",
        "    image_h = 32\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
        "    return (img/256)\n",
        " \n",
        "src = []\n",
        "name = []\n",
        "test = []\n",
        "image_dir = \"/content/drive/My Drive/Colab Notebooks/workspace/test/\"\n",
        "for file in os.listdir(image_dir):\n",
        "    if (file.find('.jpg') is not -1):      \n",
        "        src.append(image_dir + file)\n",
        "        name.append(file)\n",
        "        test.append(Dataization(image_dir + file))\n",
        " \n",
        " \n",
        "test = np.array(test)\n",
        "model = load_model('flowers.h5')\n",
        "predict_c = model.predict_classes(test) #flower name\n",
        "predict_acc = model.predict(test) #flower accurancy\n",
        "for i in range(len(test)):\n",
        "    print(name[i] + \" : , Predict : \"+ str(categories[predict_c[i]]), \", accurancy : \" + str(round(max((predict_acc[i]) * 100), 3)) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}